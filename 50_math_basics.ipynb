{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "080e93e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120a37f",
   "metadata": {},
   "source": [
    "# Mathematics Basics\n",
    "\n",
    "**With `NumPy, pandas & PyTables`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0806b7ff",
   "metadata": {},
   "source": [
    "&copy; Dr. Yves J. Hilpisch | The Python Quants GmbH\n",
    "\n",
    "http://tpq.io | [training@tpq.io](mailto:trainin@tpq.io) | [@dyjh](http://twitter.com/dyjh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc89f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python and Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390dec04",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Python per se is _not_ a Big Data technology. However, Python in combination with packages like `pandas` or `PyTables` allows the management and the analysis of quite large data sets.\n",
    "\n",
    "For our purposes, we define Big Data as a (number of) **object(s)** and/or **data file(s)** that do(es) _not_ fit into the memory of a single computer (server, node, etc.) &mdash; whatever hardware you are using for data analytics. On such a data file, typical analytics and computational tasks, like counting, aggregation and selection shall be implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e61c47",
   "metadata": {},
   "source": [
    "## Large Scale Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c1343",
   "metadata": {},
   "source": [
    "Computation = Mathematics + Programming + Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebdf03b",
   "metadata": {},
   "source": [
    "Large Scale Computation = Mathematics + Programming + Large Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed864f54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Out-of-Memory Analytics with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4ef45",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "Sometimes operations on `NumPy ndarray` objects generate so many temporary objects that the available memory does not suffice to finish the desired operation. An example might be `a.dot(a.T)`, i.e. the dot product of an array `a` with iteself transposed.\n",
    "\n",
    "Such an operation needs memory for **three arrays**: `a`, `a.T` and `a.dot(a.T)`. If the array `a` is sufficiently large, say 50% of the free memory, such an operation is impossible with the usual approach.\n",
    "\n",
    "A solution is to work with **disk-based arrays** and to use **memory maps** of these arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15330d01",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some **imports** first and a check of the **free memory**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/tpq-classes/mathematics_basics.git\n",
    "import sys\n",
    "sys.path.append('mathematics_basics')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd602e7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc1fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RAM % used:', psutil.virtual_memory()[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c88f32a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee3fb8",
   "metadata": {},
   "source": [
    "We generate a larger `NumPy ndarray` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40300ca4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = 10000\n",
    "n = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e716bfc8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "a = rng.standard_normal((m, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478dbcb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f5965",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Checking **memory** again &ndash; and that the object (reference pointer) indeed **owns the data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd86993e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa67fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.flags.owndata\n",
    "  # the object owns the in-memory data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e31a9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Simple **operations** on the in-memory `ndarray` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e67322",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a[:3, :3]\n",
    "  # sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b252ed",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%time a.mean()\n",
    "  # reductions work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dcbdbb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now save this object **to disk** ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e7672",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# path = '/Users/yves/Temp/data/' \n",
    "path = '../../../data/'  # needs to be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095f326",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%time np.save(path + 'od', a)\n",
    "  # save memory array to disk (SSD)\n",
    "  # (can need less time than in-memory generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed78e4b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "... and **delete** the in-memory object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256bb2bc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "del a\n",
    "  # delete the in-memory version\n",
    "  # to free memory -- somehow ...\n",
    "  # gc does not work \"instantly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78dbfc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "psutil.virtual_memory()\n",
    "  # garbage collection does not bring that much ...\n",
    "  # memory usage has not changed significantly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188873d8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Memory Map of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1a5e8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Using the saved object, we generate a new `memmap` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1f1cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "od = np.lib.format.open_memmap(path + 'od.npy', dtype=np.float64, mode='r')\n",
    "  # open memmap array with the array file as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74861505",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "od.flags.owndata\n",
    "  # object does not own the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc86b27",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It mainly behaves the **same way** as in-memory `ndarray` objects behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a5ff9c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "od[:3, :3]\n",
    "  # compare sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73903ebe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%time od.mean()\n",
    "  # operations in NumPy as usual\n",
    "  # somewhat slower of course ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf6bd8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Memory Maps of (Intermediate) Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431284aa",
   "metadata": {},
   "source": [
    "Major memory problems with `NumPy ndarray` objects generally arise due to **temporary arrays** needed to store intermediate results. We therefore generate `memmap` objects to store intermediate and final results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd5556",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, for the **transpose of the array**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40bef4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tr = np.memmap(path + 'tr.npy', dtype=np.float64, mode='w+', shape=(n, m))\n",
    "  # memmap object for transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9d136",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%time tr[:] = od.T[:]\n",
    "  # write transpose to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9654429",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -n $path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024f536",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Second, for the **final results**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8fab29",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "re = np.memmap(path + 're.npy', dtype=np.float64, mode='w+', shape=(m, m))\n",
    "  # memmap object for result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824595be",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%time re[:] = od.dot(tr)[:]\n",
    "  # store results on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422aed3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Final Look and Cleaning Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cc28e1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Lots of data (`od + tr + re`) has been crunched/created without a real memory burden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6615100",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!ls -n $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f65b29",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!rm $path*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75236ba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using a Sub-Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d01841",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The `concurrent` module allows the use of a **separate sub-process** for callables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be810c2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import concurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aec22e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_array_on_disk(m, n):\n",
    "    # memory inefficient operation\n",
    "    a = rng.standard_normal((m, n))\n",
    "    np.save(path + 'od.npy', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee16872",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The use of such a sub-process makes sure that any memory used by the sub-process gets immediately freed after the sub-process is terminated. This leaves the **free memory of the current process** mainly unchanged. Avoids \"unpredictable\" behaviour of `Python` garbage collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8cc63",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1227f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with concurrent.futures.ThreadPoolExecutor() as subprocess:\n",
    "    subprocess.submit(generate_array_on_disk, m, n).result()\n",
    "  # separate sub-process is started, the callable is executed\n",
    "  # the process with all its memory usage is killed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6a309",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "psutil.virtual_memory()\n",
    "  # meanwhile memory was freed again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a4bb7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Final look and clean-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722670fe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!ls -n $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a2529",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!rm $path*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822e532",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Processing (Too) Large CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747730bf",
   "metadata": {},
   "source": [
    "We generate a CSV file on disk that is **too large** to fit into memory. We process this file with the help of `pandas` and `PyTables`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0121b6e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, some imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a343011",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b781775",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Generating an Example CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b120e7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Number of **rows** to be generated for random data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3857a7d0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "N = int(1e5)\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c99ea9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Using both random **integers** as well as **floats**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afbbf2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ran_int = rng.integers(0, 10000, size=(2, N))\n",
    "ran_flo = rng.standard_normal((2, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c356d14e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Filename for **`csv` file**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a79bed",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "csv_name = path + 'data.csv'\n",
    "csv_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b337601",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Writing the data** row by row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9bc734",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with open(csv_name, 'w') as csv_file:\n",
    "    header = 'date,int1,int2,flo1,flo2\\n'\n",
    "    csv_file.write(header)\n",
    "    for _ in range(20):\n",
    "        # 20 times the original data set\n",
    "        for i in range(N):\n",
    "            row = '%s,%i,%i,%f,%f\\n' % \\\n",
    "                    (dt.datetime.now(), ran_int[0, i], ran_int[1, i],\n",
    "                                    ran_flo[0, i], ran_flo[1, i])\n",
    "            csv_file.write(row)\n",
    "        print('Size on disk:', os.path.getsize(csv_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db525e5b",
   "metadata": {},
   "source": [
    "**Excursion**: If only the numerical data is to be written to disk, using `np.savetext()` can be more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran = np.vstack((ran_int, ran_flo)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9cbb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc271af",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "csv_name_ = path + 'data_.csv'\n",
    "csv_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ea1d9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "np.savetxt(csv_name_, ran, delimiter=',')  # just a single data set (not 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203da878",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Delete** the original `NumPy ndarray` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf07f8c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "del ran\n",
    "del ran_int\n",
    "del ran_flo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ff1a9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Reading some rows** to check the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3672da",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open(csv_name, 'r') as csv_file:\n",
    "    for _ in range(5):\n",
    "        print(csv_file.readline(), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2dbf9d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#with open(csv_name_, 'r') as csv_file:\n",
    "#    for _ in range(5):\n",
    "#        print(csv_file.readline(), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec53d41",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reading and Writing with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206bc1df",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The filename for the `pandas HDFStore`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -n $path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa2a6ef",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd_name = path + 'data.h5p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72453a6b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "h5 = pd.HDFStore(pd_name, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f1dea0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`pandas` allows to read data from (large) files chunk-wise via a **file-iterator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bde8ed",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "it = pd.read_csv(csv_name, iterator=True, chunksize=N / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a6bf8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reading and storing the data **chunk-wise**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98dbbc0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, chunk in enumerate(it):\n",
    "    h5.append('data', chunk)\n",
    "    if i % 20 == 0:\n",
    "        print('Size on disk:', os.path.getsize(pd_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64062c77",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The resulting `HDF5` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e378ea",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(h5.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ff0d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Disk-Based Analytics with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7901c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The **disk-based** `pandas DataFrame` mainly behaves like an **in-memory** object &ndash; but these operations are not memory efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0531241",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%time h5['data'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2be0d8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Data selection and plotting** works as with regular `pandas DataFrame` objects &ndash; again not really memory efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import plt\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599670a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%time h5['data']['flo2'][0:N:1000].cumsum().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0658a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "h5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b4bba",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The major reason is that the `DataFrame` **data structure is broken up** (e.g. columns) during storage. For analytics it has to be put together in-memory again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2e9df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tables as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6483f777",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "h5 = tb.open_file(path + 'data.h5p', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf2ed78",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932f63d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "h5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef2a56",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reading with pandas and Writing with PyTables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b3b02",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The `PyTables` database file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305eb988",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tables as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f05da",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tb_name = path + 'data.h5t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c66dfb4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "h5 = tb.open_file(tb_name, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0758c9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Using a **`rec array` object** of `NumPy` to provide the row description for the `PyTables` table. To this end, a **custom `dtype` object** is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa2daf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dty = np.dtype([('date', 'S26'), ('int1', '<i8'), ('int2', '<i8'),\n",
    "                                 ('flo1', '<f8'), ('flo2', '<f8')])\n",
    "  # change dtype for date from object to string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2deefd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Adding **compression** to the mix (less storage, better backups, better data transfer, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074bce4b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "filters = tb.Filters(complevel=2, complib='blosc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4768e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Again **reading and writing chunk-wise**, this time appending to a `PyTables table` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593539cf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "it = pd.read_csv(csv_name, iterator=True, chunksize=N / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dce54ee",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tab = h5.create_table('/', 'data',\n",
    "            np.array(it.read().to_records(index=False),\n",
    "                     dty), filters=filters)\n",
    "  # initialize table object by using first chunk and adjusted dtype\n",
    "for chunk in it:\n",
    "    tab.append(chunk.to_records(index=False))\n",
    "tab.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe6bcf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The resulting `table` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b2b5a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "h5.get_filesize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b8b73",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9543bd6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Out-of-Memory Analytics with PyTables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9982361",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Data on disk** can be used as if it would be both _in-memory_ and _uncompressed_. De-compression is done at run-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605f424",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tab[N:N + 3]\n",
    "  # slicing row-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17827e76",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tab[N:N + 3]['date']\n",
    "  # access selected data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78914c98",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Counting** of rows is easily accomplished (although here not really needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ecc4f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%time len(tab[:]['flo1'])\n",
    "  # length of column (object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787bdff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Aggregation** operations, like summing up or calculating the mean value, are another application area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3dc7a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%time tab[:]['flo1'].sum()\n",
    "  # sum over column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40122fe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%time tab[:]['flo1'].mean()\n",
    "  # mean over column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cab7cc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Typical, `SQL`-like, **conditions and queries** can be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2c135",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%time sum([row['flo2'] for row in tab.where('(flo1 > 3) & (int2 < 1000)')])\n",
    "  # sum combined with condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f071b64",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "h5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024487a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d8cd5",
   "metadata": {},
   "source": [
    "All operations have been on data sets that do not fit (if uncompressed) into the memory of the machine they haven been implemented on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373fad06",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!ls -n $path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88080cd4",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Using compression of course reduces the size of the `PyTables table` object relative to the `csv` and the `pandas HDFStore` files. This might, in certain circumstances, lead to file sizes that would again fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a77ed7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!rm $path*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7395f818",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac74d9f",
   "metadata": {},
   "source": [
    "`Python` and packages like **`NumPy, pandas, PyTables`** provide useful means and approaches to circumvent the limitations of free memory on a single computer (node, server, etc.).\n",
    "\n",
    "Key to the **performance of such out-of-memory operations** are mainly the storage hardware (speed/capacity), the data format used (e.g. `HDF5` vs.  relational databases) and in some scenarios also the use of performant compression algorithms.\n",
    "\n",
    "Reading writing speed of **`SSD` hardware** is evolving fast:\n",
    "\n",
    "* status quo: **3+GB/s** reading/writing (e.g. MacBook 2020)\n",
    "* available: **6+GB/s** reading/writing (e.g. latest SSDs 2021)\n",
    "\n",
    "Check out [Fastest SSD Drives](https://www.gamingpcbuilder.com/ssd-ranking-the-fastest-solid-state-drives/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33f564",
   "metadata": {},
   "source": [
    "<img src=\"http://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n",
    "\n",
    "<a href=\"http://tpq.io\" target=\"_blank\">http://tpq.io</a> | <a href=\"http://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:training@tpq.io\">training@tpq.io</a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}